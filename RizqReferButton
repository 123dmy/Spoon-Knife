
                                              <a href="mailto:mubashir18@live.com"><img src="https://storage.googleapis.com/referworkspace-asset/img/digitalbuttons/digital_button_gmail_en.png" /></a>
                          

 
At Google, we’ve long believed that being bold on technological advancements means being responsible from the start – and the same holds true for artificial intelligence, or AI.

 
At its heart, AI is computer programming that learns and adapts. As a developer, you know that AI isn’t the solution to every problem, but understand that its potential to help streamline workflows, improve productivity, and automate repetitive tasks is profound.

 
AI is quickly evolving. As lawmakers in Washington, D.C. and state capitals begin to make decisions around public policy and AI, it’s important they hear from you and other developers who are driving technological innovation.

 
Like with other technologies, we feel a deep responsibility to get AI right – here’s how we’re doing just that:

 
•

 	
Promoting safe and secure AI systems by putting our models through adversarial testing to mitigate risks and prevent them from being misused unethically or unfairly.

•

 	
Building trust in AI systems by following the AI Principles we developed in 2018, establishing a governance team, fulfilling the voluntary AI commitments we made at the White House, and more.
